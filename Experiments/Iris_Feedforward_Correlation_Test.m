% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created Tue Mar 24 22:02:54 EDT 2015
%
% This script assumes these variables are defined:
%
%   irisInputs - input data.
%   irisTargets - target data.

clear all;
load iris_dataset.mat


phi = mapminmax(irisInputs)';
% Normalize the data
%mean_sample = mean(phi);
%phi = phi - ones(size(phi, 1), 1)*mean_sample;
%phi_std = sqrt(var(phi));
%std_mat = ones(size(phi, 1), 1)*sqrt(var(phi));
%phi = phi ./ std_mat;

% Scale everything between -1 and 1
%phi = phi ./ max(max(abs(phi)));

t = irisTargets;

sc_error = [];
corr_normal_avg = [];
corr_regen_avg = [];
corr_delay_avg = [];


    
    numNodesPerLayer = 2;
numInputs = size(phi, 2);
bitstreamLength = 30000;

  % Generate a set of weights to be used with all the neurons
    w_all = rand(numInputs+1)/10;
    
for numLayers = 1:1:10
    numLayers
% Create a Pattern Recognition Network
%numLayers = 50;  % Number of layers including hidden and output layers



%  Now that the network is trained, we can extract the weights and use
%  these in our stochastic network

% We can extract the biases for the (ith) layer with: net.b{i}  The result
% will be an (M) dimensional vector where M is the number of neurons in the
% (ith) layer.



  
    
space = 5000:1000:5000;
for N = space%  Stochastic number length
    
    N
    % Create a matrix which holds the weights for each neuron.  This matrix
    % will be as (bit, weight, neuron, layer).  So, we need a 3 dimensional matrix.
    
    % To correctly generate the weights we need to generate the numbers and
    % then convert these to binary strings.
    

    
    %w_i_dec = 0 + rand(numInputs+1, numNodesPerLayer)/10; % Generate all positive weights between .6 and 1.
    w_i_sc = zeros(N, numInputs+1, numNodesPerLayer);
    for input = numInputs+1
        for node = 1:numNodesPerLayer
            for n = 1:N
                w_i_sc(n, input, node) = rand(1) < w_all(input);
            end
        end
    end
    
   % w_ho_dec = 0 + rand(numNodesPerLayer+1, numNodesPerLayer, numLayers-1)/10;
    w_ho_sc = zeros(N, numNodesPerLayer+1, numNodesPerLayer, numLayers-1);
    for weight = 1:numNodesPerLayer+1
        for neuron = 1:numNodesPerLayer
            for layer = 1:numLayers-1
                for n = 1:N
                    w_ho_sc(n, weight, neuron, layer) = rand(1) < w_all(input);
                end
            end
        end
    end
    
   
   

    FSM_STATES_I = ceil(2*length(numInputs+1));
    FSM_STATES_HO = ceil(2*length(numNodesPerLayer+1));
    AVG_STEPS = 1;
    
    results = [];
    corr_normal = [];
    corr_regen = [];
    corr_delay = [];
    sample_count = size(phi, 1);
    sample_count = 1;
    for i = 1:sample_count
        i;
        % Get the sample point
        x = (phi(i,:)');

        % Convert the input to the Uni-Polar range
        dec_signals_squished = BIPOL_2_UNIPOL([1; x]);
        
        % Convert the decimal values to stochastic numbers
        sc_signals = DEC2SC_ARRAY(dec_signals_squished, N);
        
        % Start the feedforward propogation
        % At the output of each layer we should get a vector which represents
        % the input to the next layer
        current_input_normal = sc_signals;
        current_input_regen = sc_signals;
        current_innput_delay = sc_signals;
        current_output_normal = zeros(numNodesPerLayer, N);
        current_output_regen = zeros(numNodesPerLayer, N);
        current_output_delay = zeros(numNodesPerLayer, N);
        for layer = 1:numLayers
            for node = 1:numNodesPerLayer
                
                %  Differentiate between the input layer weights and other
                %  layers
                if(layer == 1)
                    % For the first layer the three correlation types
                    % remain the same.
                    current_output_normal(node, :) = NEURON(current_input_normal, w_i_sc(:, :, node)', FSM_STATES_I, false, false);
                    current_output_regen(node, :) = current_output_normal(node, :);
                    current_output_delay(node, :) = current_output_normal(node, :);
                else
                    current_output_normal(node, :) = NEURON(current_input_normal, w_ho_sc(:, :, node, layer-1)', FSM_STATES_HO, false, false);
                    current_output_regen(node, :) = NEURON(current_input_regen, w_ho_sc(:, :, node, layer-1)', FSM_STATES_HO, false, false);
                    current_output_delay(node, :) = NEURON(current_input_delay, w_ho_sc(:, :, node, layer-1)', FSM_STATES_HO, false, false);
                end
 
            end
            
            % Update the current input
            current_output_regen(1, :) = DEC2SC_ARRAY(S2D_ARRAY(current_output_regen(1,:)), N);
            current_output_delay(1, :) = DELAY(current_output_delay(1,:));
            
            current_input_normal = [ones(1, N); current_output_normal];
            current_input_regen = [ones(1, N); current_output_regen];
            current_input_delay = [ones(1, N); current_output_delay];
            
            % Since for now we are only assuming two layers, delay /
            % regeneraete the first element of this vector
            
        end
        
        corr_normal = [corr_normal sc_correlation(current_output_normal(1,:), current_output_normal(2,:))];
        corr_regen = [corr_regen sc_correlation(current_output_regen(1,:), current_output_regen(2,:))];
        corr_delay = [corr_delay sc_correlation(current_output_delay(1,:), current_output_delay(2,:))];

    end
    
        corr_normal_avg = [corr_normal_avg mean(abs(corr_normal))];
        corr_delay_avg = [corr_delay_avg  mean(abs(corr_delay))];
        corr_regen_avg = [corr_regen_avg mean(abs(corr_regen))];
        
    
    % Plot the histograms
    %figure(1);
    %range = linspace(-200, 200, 21);
    %subplot(3, 1, 1)
    %hist(round((corr_normal*10000)), range)
    %set(get(gca,'child'),'FaceColor',[255/255	215/255	0]);
    %title('Normal')
    
    %subplot(3, 1, 2)
    %hist(round((corr_delay*10000)), range)
    %set(get(gca,'child'),'FaceColor',[205/255	55/255	0]);
    %title('Delay')
    
    %subplot(3, 1, 3)
    %hist(round((corr_regen*10000)), range)
    %findobj(gca,'Type','patch');
    %set(get(gca,'child'),'FaceColor',[255/255	127/255	0]);
    %title('Regeneration')
    
    % Plot the averages
%     figure1 = figure(2);
%     axes1 = axes('Parent',figure1,...
%     'XTickLabel',{'Normal','Delay','Regeneration'},...
%     'XTick',[1 2 3]);
% box(axes1,'on');
% hold(axes1,'all');
% 
%     b1 = bar(1, mean(abs(corr_normal)))
%     hold on;
%     b2 = bar(2, mean(abs(corr_delay)))
%     hold on;
%     b3 = bar(3, mean(abs(corr_regen)))
% 
% 
%     set(b1, 'FaceColor', [255/255	215/255	0]);
%     set(b2, 'FaceColor', [205/255	55/255	0]);
%     set(b3, 'FaceColor', [255/255	127/255	0]);

    
end
end

plot(1:10, corr_normal_avg, 'Color', [255/255;215/255;0]);
hold on;
plot(1:10, corr_delay_avg, 'Color', [205/255 55/255 0]);
hold on;
plot(1:10, corr_regen_avg,  'Color', [255/255 127/255 0]);
legend('Normal', 'Delay', 'Regeneration');


% Create xlabel
xlabel('Hidden Layers','FontWeight','bold','FontSize',16);

% Create ylabel
ylabel('SCC','FontWeight','bold','FontSize',16);

% Create title
title('1 - 20 Hidden Layers with Weights in [0 .1]   ','FontWeight','bold',...
    'FontSize',16);

% Test the network on all the data
output = sim(net, phi');
output = (output - ones(3, 1)*max(output)) >= 0;
net_error = sum(sum(abs((output' - t')), 2) > 0) / length(t);

% Test the Network
y = net(phi');
e = gsubtract(t,y);
tind = vec2ind(t);
yind = vec2ind(y);
percentErrors = sum(tind ~= yind)/numel(tind);
performance = perform(net,t,y)

% Recalculate Training, Validation and Test Performance
trainTargets = t .* tr.trainMask{1};
valTargets = t  .* tr.valMask{1};
testTargets = t  .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y)
valPerformance = perform(net,valTargets,y)
testPerformance = perform(net,testTargets,y)

% View the Network
view(net)

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, plotconfusion(t,y)
%figure, plotroc(t,y)
%figure, ploterrhist(e)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
if (false)
  % Generate MATLAB function for neural network for application deployment
  % in MATLAB scripts or with MATLAB Compiler and Builder tools, or simply
  % to examine the calculations your trained neural network performs.
  genFunction(net,'myNeuralNetworkFunction');
  y = myNeuralNetworkFunction(x);
end
if (false)
  % Generate a matrix-only MATLAB function for neural network code
  % generation with MATLAB Coder tools.
  genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
  y = myNeuralNetworkFunction(x);
end
if (false)
  % Generate a Simulink diagram for simulation or deployment with.
  % Simulink Coder tools.
  gensim(net);
end
